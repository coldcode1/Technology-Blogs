truncate table article;

INSERT INTO `article` (`id`, `user_id`, `article_type`, `title`, `short_title`, `picture`, `summary`, `category_id`, `source`, `source_url`, `offical_stat`, `topping_stat`, `cream_stat`, `status`, `deleted`, `create_time`, `update_time`) 
VALUES
(1, 1, 1, 'RabbitMQ实战1: 代码实现queue、exchange的申明', '', '', 'rabbiMQ实战: queue初始配置、Topic的exchange实现通知消息', 1, 2, '', 0, 0, 0, 1, 0, '2023-10-17 09:41:40', '2023-12-01 14:11:33'),
(2, 1, 1, '技术博客园-如何保证高可用性', '', '', '在技术博客园中，如何保证高可用性', 1, 2, '', 0, 1, 0, 1, 0, '2023-08-17 10:04:09', '2023-08-17 10:04:09'),
(3, 1, 1, 'MVC中的过滤器、拦截器详解', '', '', 'MVC中常用的过滤器、拦截器详细解析、实战。以及可能存在的问题。', 1, 2, '', 0, 0, 0, 1, 0, '2023-08-21 08:52:01', '2023-08-21 08:52:34'),
(4, 1, 1, '技术博客园开发plan', '', '', '记录 技术博客园功能及各模块的实现想法', 8, 2, '', 0, 1, 0, 1, 0, '2023-08-21 09:13:59', '2023-08-22 09:58:52'),
(2424530378819585, 1, 1, '原创教程：手写Netty+Zookeeper的远程调用RPC组件', '', '', '手写NettyZookeeper的远程调用RPC组件的原创教程', 7, 2, '', 0, 1, 0, 1, 0, '2024-05-01 08:02:51', '2025-05-01 08:03:03'),
(2424549811030017, 1, 1, 'TCP 中的 Nagle 算法是什么？有什么作用？', '', '', 'Nagle算法是TCP协议中的一种优化算法,用于提高网络利用效率。', 1, 2, '', 0, 0, 0, 1, 0, '2023-09-01 13:11:43', '2023-09-01 13:11:43'),
(2424600050855936, 1, 1, '记录一个@Builder导致的反序列化错误！', '', '', '记录一个Builder导致的反序列化错误！', 1, 2, '', 0, 0, 0, 1, 0, '2023-09-02 15:20:46', '2023-09-02 15:20:46'),
(2424700051904512, 1, 1, 'rabbitmq+定时任务实现邮件发送，保证消息100%投递成功', '', '', 'rabbitmq定时任务实现邮件发送，保证消息100投递成功', 1, 2, '', 0, 1, 0, 1, 0, '2024-07-03 04:35:57', '2024-07-03 04:35:57');


INSERT INTO `article_detail` (`id`, `article_id`, `version`, `content`, `deleted`, `create_time`, `update_time`) 
VALUES
(24, 1, 1, '关键点在于：部署在新机器上时，不可能专门去rabbitMQ管理中手动配置queue等。所以需要在代码中直接实现。\n\n1、在配置文件中写入基础的配置信息\n\n​	由于我工作原因，会涉及到在不同电脑上coding（笔记本没有安装rabbitMQ），为了方便使用配置文件中的switchFlag进行切换，使用`@ConditionalOnProperty(value = \"rabbitmq.switchFlag\")`便可以自由切换\n\n```\nrabbitmq:\n  host: 127.0.0.1\n  port: 5672\n  username: guest\n  passport: guest\n  virtualhost: /\n  switchFlag: true\n  pool_size: 10\n```\n\n2、代码实现连接、channel。以及申明exchange、queue。\n\n本来exchange都是direct的，分别是点赞和收藏文章。现在为了利用rabbitMQ实现一个邮件发送的功能，所需要新增一个queue。联想到使用消息队列要做的事情越来越多，所以进行了一个封装，将关于文章的点赞、收藏等通知信息封装在notify中，统一用topic的exchange发送。\n\n（被注释掉的是之前，对点赞、收藏分别申明的queue）\n\n```\npublic class RabbitMqAutoConfig implements ApplicationRunner {\n    @Resource\n    private RabbitmqService rabbitmqService;\n\n    @Autowired\n    private RabbitmqProperties rabbitmqProperties;\n\n    @Override\n    public void run(ApplicationArguments args) throws Exception {\n        String host = rabbitmqProperties.getHost();\n        Integer port = rabbitmqProperties.getPort();\n        String userName = rabbitmqProperties.getUsername();\n        String password = rabbitmqProperties.getPassport();\n        String virtualhost = rabbitmqProperties.getVirtualhost();\n        Integer poolSize = rabbitmqProperties.getPoolSize();\n\n        RabbitmqConnectionPool.initRabbitmqConnectionPool(host, port, userName, password, virtualhost, poolSize);\n        RabbitmqConnection connection = RabbitmqConnectionPool.getConnection();\n        Channel channel = connection.getConnection().createChannel();\n        // 声明exchange中的消息为可持久化，不自动删除\n        // channel.exchangeDeclare(CommonConstants.EXCHANGE_NAME_DIRECT, BuiltinExchangeType.DIRECT, true, false, null);\n\n        channel.exchangeDeclare(CommonConstants.EXCHANGE_NAME_TOPIC, BuiltinExchangeType.TOPIC, true, false, null);\n\n        // 声明点赞的消息队列\n//        channel.queueDeclare(CommonConstants.QUERE_NAME_PRAISE, true, false, false, null);\n//        //绑定队列到交换机\n//        channel.queueBind(CommonConstants.QUERE_NAME_PRAISE, CommonConstants.EXCHANGE_NAME_DIRECT, CommonConstants.QUERE_KEY_PRAISE);\n//\n//        // 声明收藏的消息队列\n//        channel.queueDeclare(CommonConstants.QUERE_NAME_COLLECT, true, false, false, null);\n//        //绑定队列到交换机\n//        channel.queueBind(CommonConstants.QUERE_NAME_COLLECT, CommonConstants.EXCHANGE_NAME_DIRECT, CommonConstants.QUERE_KEY_COLLECT);\n\n        channel.queueDeclare(CommonConstants.QUERE_NAME_NOTIFY, true, false, false, null);\n        channel.queueBind(CommonConstants.QUERE_NAME_NOTIFY, CommonConstants.EXCHANGE_NAME_TOPIC, CommonConstants.QUERE_KEY_NOTIFY);\n        channel.close();\n        RabbitmqConnectionPool.returnConnection(connection);\n        AsyncUtil.execute(() -> rabbitmqService.processConsumerMsg());\n    }\n}\n```\n\n3、通过注解`@RabbitListener(queues = CommonConstants.QUERE_NAME_NOTIFY)`实现一个监听器，\n\n```java\n@RabbitListener(queues = CommonConstants.QUERE_NAME_NOTIFY)\npublic void notifyMesSaveAndSubmit(String message,  @Header(\"amqp_receivedRoutingKey\") String routingKey) {\n    try {\n        log.info(\"Consumer msg: {}\", message);\n\n        if(routingKey.equals(CommonConstants.QUERE_KEY_COLLECT)){\n            notifyService.saveArticleNotify(JsonUtil.toObj(message, UserFootDO.class), NotifyTypeEnum.COLLECT);\n        }else if (routingKey.equals(CommonConstants.QUERE_KEY_PRAISE)){\n            notifyService.saveArticleNotify(JsonUtil.toObj(message, UserFootDO.class), NotifyTypeEnum.PRAISE);\n        }\n    } catch (Exception e) {\n        log.info(\"错误信息:{}\", e.getMessage());\n    }\n}\n```\n\n而这个ApplicationRunner的运行是在RabbitListen的bean之后的，导致一直在报bug。一个简单的解决办法是：先手动注释listen的注解，声明exchange和queue之后，再重新运行代码。\n\n然而部署在服务器上，很显然这个方法并不可行。\n\n4、利用bean的生命周期\n\n我们可以利用bean的生命周期来解决这个问题，将init方法放入到监听RabbitMsg的bean中，便可以解决这个问题。\n\n```java\n@PostConstruct\nprivate void init(){\n    // \n}\n```\n\n特别地，我们没有直接建立rabbitMQ的connection，而是在init的过程中，创建了一个pool（一个阻塞队列），方便连接的服用。\n\n```java\npublic static void initRabbitmqConnectionPool(String host, int port, String userName, String password,\n                                         String virtualhost,\n                                       Integer poolSize) throws InterruptedException, IOException {\n    pool = new LinkedBlockingQueue<>(poolSize);\n    for (int i = 0; i < poolSize; i++) {\n        pool.add(new RabbitmqConnection(host, port, userName, password, virtualhost));\n    }\n}\n```\n\n这是rabbitMQ实战的第一篇，也是最基础的实现，在这个过程中，也参考了很多大佬的博客和代码，可能没法一一贴上来，在此向广大开源的技术人致谢！后续还会继续更新文章~作为我自己学习过程中的记录。', 0, '2023-08-17 09:41:40', '2023-08-17 09:41:40'),
(11, 2, 1, '\n这是一个说大不大说小也不小的问题，在实际中，同学们可能也经常被面试官问到，如何保证一个高可用性。往小了说，从我个人记录博客的一个应用而言，他仅仅是一个单体项目，然后并没有多高的qps（甚至可能也只有我点击进来看），所以即使请求全部打到mysql中，也没什么问题。\n\n但是实际上，这反应了一个人对技术的追求，去思考优雅的代码实现和可能会存在的问题，接下来我就结合技术博客园，谈论如何保证一个后端项目的高可用性。\n\n1、缓存的使用\n\n后端项目，避免不了接触数据，而大量的数据库都存放在mysql中，大家都知道缓存穿透、缓存击穿、缓存雪崩等问题。这些绝不是简单的名词，而是实际开发中必然会用到的情况。（犹记得实习的时候，用了一个**OHC堆外缓存**，上线后没有去研究缓存的**hit率**和缓存的**存储量**，被mentor指出来~~）\n\n（1）redis：主要用来存储文章。以及利用ZSet实现阅读活跃排行榜。\n\n（2）caffeine：作为本地缓存性能之王，我们用caffeine对网站的侧边栏（关于技术博客园、推荐资源、热门文章）进行了缓存，即使**热门文章**可能会更改，但是采用caffeine的写后缓存便可实现定时更新功能。（这是偷懒做法，实际上，更应该做的是，一个定时器，定时更改）\n\n\n\n2、消息队列\n\n消息队列的三大优点：异步、解耦、削峰\n\n试想，当我们新发表一篇文章，可能会被很多人瞬间看到(可能不太可能，哈哈哈)，并且文章写的很好，这会导致大量的点赞，很显然，这样的高流量不能直接打到数据库中，所以采用rabbitMQ进行削峰。\n\n\n\n3、业务可用性\n\n登陆两条线：\n\n	（1）、通过微信公众号的callback接口，简化了登陆。\n	（2）、基于邮箱的注册登录。\n\n\n\n3、服务的安全性、稳定性\n\n这一点更多的是服务的安全、稳定性。比如，不可能让人轻松地注册无限个账号（通过邮箱限制），无限制的发起邮箱验证码（设置时间限制）等等。\n\n\n\n', 0, '2023-08-17 10:04:09', '2023-08-17 10:04:09'),
(14, 3, 1, '\n### 1、过滤器与拦截器的定义\n\n​	过滤器和拦截器 均体现了`AOP`的编程思想，都可以实现诸如日志记录、登录鉴权等功能，但二者的不同点也是比较多的：\n\n（1）过滤器`Filter` 的使用要依赖于`Tomcat`等容器，导致它只能在`web`程序中使用。而在一个mvc应用中，过滤器在Dispatchservlet之前，而拦截器在Dispatchservlet之后，具体的ControllerHandle之前。（这里讨论的是pre，post的顺序是反着的，具体的图示见第二节）。简单的图示如下：\n\n![img](https://technology-blogs.oss-cn-shanghai.aliyuncs.com/techonologyblogs/ceea6a675d321c2017141010a525888a.png)\n\n（2）**过滤器**和**拦截器**底层实现方式大不相同，**过滤器**是基于***函数回调（FilterChain）***的，**拦截器**则是基于Java的***反射机制（动态代理）***实现的。\n\n​	`FilterChain`是一个回调接口，`ApplicationFilterChain`是它的实现类， 这个实现类内部也有一个 `doFilter()` 方法就是回调方法。实际上，执行过滤器的doFilter就是通过`ApplicationFilterChain`去实现的，\n\n（3）**拦截器可以获取IOC容器中的各个bean，而过滤器不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。**\n\n这是因为`spring`容器初始化`bean`对象的顺序是***listener-->filter-->servlet***。如果在一些特定场景中确实需要在过滤器中使用bean。\n\n### 2、过滤器、拦截器在一个web应用中具体的位置\n\n​	这里有一个细节，`postHandle`发生在`Controller`方法处理完之后，`DispatcherServlet`进行视图的渲染之前，也就是说在这个方法中你可以对`ModelAndView`进行操作。而`afterCompletion`是在视图渲染之后。\n\n![img](https://technology-blogs.oss-cn-shanghai.aliyuncs.com/techonologyblogs/565d30037c97b0278af24945fb9e15ea.png)\n\n### 3、过滤器与拦截器的应用方案\n\n#### 过滤器：\n\n##### 	（1）实现`Filter`接口\n\n```java\npublic class ReqRecordFilter implements Filter {\n\n    @Override\n    public void init(FilterConfig filterConfig) {\n    }\n\n    @Override\n    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {\n        // 逻辑处理\n        filterChain.doFilter(request, servletResponse);\n    }\n\n    @Override\n    public void destroy() {\n    }\n}\n```\n\n##### 	（2）\n\n##### 方式1.使用`@WebFilter`注解。\n\n##### *注意：这种方式可能顺序order不生效！*\n\n​	Filter实现类如下所示。此外这种方式需要在启动类上面加上`@ServletComponentScan`注解。\n\n```java\n@WebFilter(urlPatterns = \"/*\", filterName = \"reqRecordFilter\", asyncSupported = true)\npublic class ReqRecordFilter implements Filter {\n    //\n}\n```\n\n##### 方式2.注册实现的filter过滤器\n\n​	Filter实现类如下所示。\n\n```java\n@Component\npublic class ReqRecordFilter implements Filter {\n    //\n}\n```\n\n​	通过配置类，配置一个bean，如下所示：\n\n```\n@Bean\npublic FilterRegistrationBean<Filter> orderFilter(){\n    FilterRegistrationBean<Filter> registrationBean = new FilterRegistrationBean<>();\n    registrationBean.setFilter(new MyTestFilter());\n    registrationBean.addUrlPatterns(\"/*\");\n    registrationBean.setName(\"MyTestFilter\");\n    registrationBean.setOrder(1);\n    return registrationBean;\n}\n```\n\n#### 拦截器：\n\n##### 	（1）实现拦截器`AsyncHandlerInterceptor`接口\n\n```java\n@Component\n@Slf4j\npublic class MyTestInterceptor implements AsyncHandlerInterceptor {\n    @Override\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {\n        log.info(\"MyTestInterceptor preHandle\");\n        return true;\n    }\n\n    @Override\n    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {\n        log.info(\"MyTestInterceptor postHandle\");\n    }\n\n    @Override\n    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {\n        log.info(\"MyTestInterceptor afterCompletion\");\n    }\n}\n```\n\n##### 	（2）实现`WebMvcConfigurer`接口中的`addInterceptors`方法，向其中注册拦截器\n\n```java\npublic class QuickForumApplication implements WebMvcConfigurer{\n\n    @Resource\n    private MyTestInterceptor myTestInterceptor; // MyTestInterceptor\n\n    @Override\n    public void addInterceptors(InterceptorRegistry registry) {\n        registry.addInterceptor(myTestInterceptor).addPathPatterns(\"/**\");\n    }\n```\n\n### 4、可能出现的问题及解决方案：\n\n##### 问题1\n\n​	当我们在前端通过ajax调用后端rest接口请求json数据，会导致重复发送request到后端。此时会导致访问一个页面会多次被过滤器拦截器所过滤拦截，而这会导致记录页面的PV数据出问题。\n\n这种问题有一个简单的解决方法，在请求中判断是不是ajax请求。', 0, '2023-08-21 08:52:01', '2023-08-21 08:52:01'),
(16, 4, 1, '### 一、用户模块\n\n#### 注册功能\n\n注册：通过RabbitMQ+邮件发送。实验用户的注册。\n\n通过setNx防止用户注册的并发问题。\n\n#### 登录功能\n\n（1）JWT+redis。\n\n（2）微信公众号回调\n\n\n\n### 二、侧边栏以及站点模块\n\n侧边栏通知：本地缓存caffeine存储。\n\n站点PV/UV等：在过滤器实现，通过Redis中的Hash实现，注意。过滤掉AJAX的请求防止防止多加PV。\n\n\n\n\n\n### 三、文章模块\n\n1、阅读\n\nredis中的zset存储热门项目的id。文章存储于OHC缓存中。通过分布式锁防止并发问题。\n\n\n\n\n\n### 四、热门项目\n\n\n\n### 五、算法OJ实现\n\ntodo//\n\n\n\n### 六、积分商城模块\n\ntodo//', 0, '2023-08-21 09:13:59', '2023-08-21 09:13:59'),
(18, 2424530378819585, 1, '## 手写Netty+Zookeeper的远程调用RPC组件\n\n### 一、组件总览：\n\n![img](https://camo.githubusercontent.com/5360cce1a15b186ccb818bf23c4a8ec583434fe8f31c4a484a91d58a72727216/68747470733a2f2f7368616f67657a68752e636e2f6173736574732f323032322d31312f727063322e706e67)\n\n一个完整的流程是：\n\n​	将原先具有RPC注解的服务的bean替换成代理对象！此后调用该服务，实际上都是用的代理对象，在代理对象中进行一系列的逻辑，包括组成RPC请求并且将其放入到阻塞队列、调用结果的放回、超时重拾。此外，放入阻塞队列，可以通过异步线程从阻塞队列中取来实现异步调用。\n\n​	从Zookeeper中拿到所有提供服务者的IP，并采用轮询、随机等**负载均衡**方式，获取某个提供服务者的ip，然后利用**Netty建立与服务提供者的长连接**，最后发起RPC调用请求。一个RPC调用请求首先会经过**序列化、自定义协议的编码**等操作。然后这个RPC请求到达服务端后，再经过**解码协议、反序列化**等步骤，然后调用RPC协议中定义所需要的方法，获得Response。\n\n​	这个Response同样经过自定义协议编码、序列化等操作，送往消费者。消费者再反序列化、解码协议。消费者从而获取最终的结果。\n\n\n\n### 二、Netty框架\n\n一款基于NIO实现的网络通信框架，通过Netty进行长连接通信，包括心跳检测、粘包半包等问题。\n\n```java\n// NioEventLoopGroup 是 Netty 中处理 I/O 操作的线程池。bossGroup 负责接受新的连接请求。它的线程会处理与客户端的连接相关的事件。\nNioEventLoopGroup bossGroup = new NioEventLoopGroup();\n// workerGroup 负责处理实际的 I/O 操作，比如读取和写入数据。它的线程会处理与已连接客户端的数据传输。\nNioEventLoopGroup workerGroup = new NioEventLoopGroup();\n// ServerBootstrap 是 Netty 提供的一个启动器类，用于简化服务器端的初始化过程。它是 Netty 提供的构建服务器的入口点。\nServerBootstrap bootstrap = new ServerBootstrap();\n// 使用 bootstrap.group() 方法来指定 bossGroup 和 workerGroup。第一个参数 (bossGroup) 负责接受新的连接，第二个参数 (workerGroup) 负责处理连接后的 I/O 操作。\nbootstrap.group(bossGroup, workerGroup);\n// 指定了服务器的通道类型为 NioServerSocketChannel。NioServerSocketChannel 是 Netty 提供的实现，用于处理基于 NIO 的服务器套接字通道。\nbootstrap.channel(NioServerSocketChannel.class);\n// 设置 TCP 连接选项 TCP_NODELAY 为 true。这会禁用 Nagle 算法，从而减少延迟，提高实时性，适合需要快速传输数据的场景，但可能会增加网络拥塞。\nbootstrap.option(ChannelOption.TCP_NODELAY, true);\n// SO_BACKLOG 定义了在服务器端等待接受的连接请求的队列大小。如果队列满了，后续的连接请求会被拒绝或延迟处理。\nbootstrap.option(ChannelOption.SO_BACKLOG, 1024);\nbootstrap.option(ChannelOption.SO_SNDBUF, 16 * 1024)\n        .option(ChannelOption.SO_RCVBUF, 16 * 1024)\n        // TCP 协议层的保活机制，主要用于检测连接是否断开，\n        .option(ChannelOption.SO_KEEPALIVE, true);\n\n//服务端采用单一长连接的模式，这里所支持的最大连接数和机器本身的性能有关\n// bootstrap.handler() 方法用于为 ServerBootstrap 设置一个 ChannelInitializer。\n// ChannelInitializer 是 Netty 中的一个重要概念，用于初始化每个新创建的 Channel（即网络连接）。它通常用于配置管道中的处理程序（Handlers）。\n// 这里我们为 ServerBootstrap 设置了一个 MaxConnectionLimitHandler，用于限制客户端的最大连接数。\nbootstrap.handler(new MaxConnectionLimitHandler(SERVER_CONFIG.getMaxConnections()));\n\n// childHandler 是 ServerBootstrap 类中的一个方法，用于为每个新创建的 SocketChannel（即与客户端的连接）设置处理程序（handler）。这些处理程序将处理与客户端连接相关的各种事件，如接收数据、处理请求、发送响应等。\n// childHandler 和 handler 的区别：(1)handler 用于配置服务器端的 ServerChannel，即接受连接的通道。(2)childHandler 用于配置每个 SocketChannel，即每个客户端连接的通道。\n// 分隔符解码：DelimiterBasedFrameDecoder 根据定义的分隔符将数据流切分成完整的消息，解决了粘包和半包的问题。\n// 编码和解码：RpcEncoder 和 RpcDecoder 确保了消息在传输过程中按照定义的协议格式进行编码和解码，进一步保证了数据的一致性和完整性。\nbootstrap.childHandler(new ChannelInitializer<SocketChannel>() {\n    @Override\n    protected void initChannel(SocketChannel ch) throws Exception {\n        ByteBuf delimiter = Unpooled.copiedBuffer(DEFAULT_DECODE_CHAR.getBytes());\n        ch.pipeline().addLast(new DelimiterBasedFrameDecoder(SERVER_CONFIG.getMaxServerRequestData(), delimiter));\n        ch.pipeline().addLast(new RpcEncoder());\n        ch.pipeline().addLast(new RpcDecoder());\n        // 处理逻辑:继承 ChannelInboundHandlerAdapter. 重写 channelRead() 方法，处理客户端发来的数据。实际上的长连接就是在这里不主动关闭ctx。\n        ch.pipeline().addLast(new ServerHandler());\n    }\n});\n```\n\n##### 1.长连接\n\n TCP 长连接，不需要特别的配置，因为 TCP 协议本身支持长连接，只要保持连接不关闭即可。具体来说，在上面的处理逻辑中，不主动关闭ctx。此外还进行了额外的处理：例如TCp的保活机制等等。\n\n##### 2.心跳检测\n\n##### 3.粘包半包问题\n\nTCP是一个*“流”协议*，就是没有界限的一串数据，TCP底层并不了解上层（Http）业务数据的具体含义，它会根据*TCP缓冲区的实际情况进行包的划分*。所以一个完整的包可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，再者就是所谓的TCP粘包半包问题。\n\n![avatar](https://doocs.github.io/source-code-hunter/images/Netty/TCP%E7%B2%98%E5%8C%85%E6%8B%86%E5%8C%85%E9%97%AE%E9%A2%98.png)\n\n解决策略：由于底层的 TCP 无法理解上层的业务数据，所以在底层是无法保证数据包不被拆分和重组的，这个问题只能通过上层的应用协议栈设计来解决，目前业界的主流协议的解决方案，归纳如下：\n\n1. 固定消息长度，例如，每个报文的大小为 固定长度 200 字节，如果不够，空位补空格；\n2. 在包尾使用 “回车换行符” 等特殊字符，作为消息结束的标志，例如 FTP 协议，这种方式在文本协议中应用比较广泛；\n3. 将消息分为消息头和消息体，在消息头中定义一个 长度字段 Len 来标识消息的总长度;\n4. 更复杂的应用层协议。\n\n##### Netty的解决方案：\n\n（1）利用LineBasedFrameDecoder ，工作原理是它依次遍历 ByteBuf 中的可读字节，判断看是否有 “\\n” 或者 “\\r\\n”，如果有，就以此位置为结束位置，从可读索引到结束位置区间的字节就组成了一行。它是以换行符为结束标志的解码器，支持携带结束符或者不携带结束符两种解码方式，同时支持配置单行的最大长度。如果连续读取到最大长度后仍然没有发现换行符，就会抛出异常，同时忽略掉之前读到的异常码流。\n\n```java\n    // 示例代码，其中 socketChannel 是一个 SocketChannel对象\n    socketChannel.pipeline().addLast( new LineBasedFrameDecoder(1024) );\n    socketChannel.pipeline().addLast( new StringDecoder() );\n```\n\n（2） DelimiterBasedFrameDecoder：设置默认的分隔符\n\n```java\nbootstrap.childHandler(new ChannelInitializer<SocketChannel>() {\n    @Override\n    protected void initChannel(SocketChannel ch) throws Exception {\n        ByteBuf delimiter = Unpooled.copiedBuffer(DEFAULT_DECODE_CHAR.getBytes());\n        ch.pipeline().addLast(new DelimiterBasedFrameDecoder(SERVER_CONFIG.getMaxServerRequestData(), delimiter));\n    }\n```\n\n（3）FixedLengthFrameDecoder：自动完成对定长信息的解码\n\n\n\n### 三、SPI机制\n\ndubbo中的spi机制，可以实现接口的多个实现类，并且在真正调用的时候才进行实例化。\n\n在此以序列化为例，说明如何实现dubbo中的spi机制：\n\n```java\n// 1.从配置中读取真正采用的序列化方式\nString serverSerialize = SERVER_CONFIG.getServerSerialize();\n// 2.找到Meta-INF.easu-rpc.SerializeFactory下面所有的实现类\nEXTENSION_LOADER.loadExtension(SerializeFactory.class);\nLinkedHashMap<String, Class<?>> serializeMap = EXTENSION_LOADER_CLASS_CACHE.get(SerializeFactory.class.getName());\nClass<?> serializeClass = serializeMap.get(serverSerialize);\nif (serializeClass == null) {\n    throw new RuntimeException(\"no match serializeClass for \" + serverSerialize);\n}\n// 3.实例化序列化类\nSERVER_SERIALIZE_FACTORY = (SerializeFactory) serializeClass.newInstance();\n```\n\n在`ExtensionLoader`实现加载所有的实现类，但***只进行class文件的加载，而不进行对象实例化***\n\n```java\npublic class ExtensionLoader {\n\n    public static String EXTENSION_LOADER_DIR_PREFIX = \"META-INF/easy-rpc/\";\n\n    public static Map<String, LinkedHashMap<String, Class<?>>> EXTENSION_LOADER_CLASS_CACHE = new ConcurrentHashMap<>();\n\n    public void loadExtension(Class<?> clazz) throws IOException, ClassNotFoundException {\n        if (clazz == null) {\n            throw new IllegalArgumentException(\"class is null!\");\n        }\n        String spiFilePath = EXTENSION_LOADER_DIR_PREFIX + clazz.getName();\n        ClassLoader classLoader = this.getClass().getClassLoader();\n        Enumeration<URL> enumeration = classLoader.getResources(spiFilePath);\n        while (enumeration.hasMoreElements()) {\n            URL url = enumeration.nextElement();\n            InputStreamReader inputStreamReader = new InputStreamReader(url.openStream());\n            BufferedReader bufferedReader = new BufferedReader(inputStreamReader);\n            String line;\n            LinkedHashMap<String, Class<?>> classMap = new LinkedHashMap<>();\n            while ((line = bufferedReader.readLine()) != null) {\n                //如果配置中加入了#开头则表示忽略该类无需进行加载\n                if (line.startsWith(\"#\")) {\n                    continue;\n                }\n                String[] lineArr = line.split(\"=\");\n                String implClassName = lineArr[0];\n                String interfaceName = lineArr[1];\n                classMap.put(implClassName, Class.forName(interfaceName));\n            }\n            //只会触发class文件的加载，而不会触发对象的实例化\n            if (EXTENSION_LOADER_CLASS_CACHE.containsKey(clazz.getName())) {\n                //支持开发者自定义配置\n                EXTENSION_LOADER_CLASS_CACHE.get(clazz.getName()).putAll(classMap);\n            } else {\n                EXTENSION_LOADER_CLASS_CACHE.put(clazz.getName(), classMap);\n            }\n        }\n    }\n}\n```\n\n在META-INF/easy-rpc/com.shaogezhu.easy.rpc.core.serialize.SerializeFactory中写入以下信息。这个一长串的名字便是接口的包引用地址。\n\n```\nfastJson=com.shaogezhu.easy.rpc.core.serialize.fastjson.FastJsonSerializeFactory\nhessian=com.shaogezhu.easy.rpc.core.serialize.hessian.HessianSerializeFactory\njdk=com.shaogezhu.easy.rpc.core.serialize.jdk.JdkSerializeFactory\nkryo=com.shaogezhu.easy.rpc.core.serialize.kryo.KryoSerializeFactory\n```\n\n### 四、Zookeeper注册中心\n\n首先通过SPI机制，创建了Zookeeper注册的实例。\n\n```java\npublic ZookeeperRegister() {\n    String registryAddr = CLIENT_CONFIG != null ? CLIENT_CONFIG.getRegisterAddr() : SERVER_CONFIG.getRegisterAddr();\n    this.zkClient = new CuratorZookeeperClient(registryAddr);\n}\n```\n\n服务提供者的注册：的URL暴露给注册中心，进行服务注册：\n\n```java\npublic void register(URL url) {\n    // 确保 Zookeeper 中存在一个根节点 ROOT，如果不存在则创建它。\n    if (!zkClient.existNode(ROOT)) {\n        // 创建一个持久化\n        zkClient.createPersistentData(ROOT, \"\");\n    }\n    String urlStr = URL.buildProviderUrlStr(url);\n    if (zkClient.existNode(getProviderPath(url))) {\n        // 如果已经存在则删除,这样做的目的是避免重复注册同一个服务或清理过时的信息。\n        zkClient.deleteNode(getProviderPath(url));\n    }\n    // 创建一个零时的\n    zkClient.createTemporaryData(getProviderPath(url), urlStr);\n    super.register(url);\n}\n```\n\n服务消费者的注册：\n\n```java\n@Override\npublic void subscribe(URL url) {\n    if (!this.zkClient.existNode(ROOT)) {\n        zkClient.createPersistentData(ROOT, \"\");\n    }\n    String urlStr = URL.buildConsumerUrlStr(url);\n    if (zkClient.existNode(getConsumerPath(url))) {\n        zkClient.deleteNode(getConsumerPath(url));\n    }\n    zkClient.createTemporarySeqData(getConsumerPath(url), urlStr);\n    super.subscribe(url);\n}\n```\n\n服务节点的监控：\n\n消费者注册后，需要对服务节点进行监控，包括目录的子节点变化以及各个服务提供者的状态信息变化：\n\n```java\npublic void doAfterSubscribe(URL url) {\n    //监控服务提供者目录的子节点变化，发现新的服务提供者\n    String newServerNodePath = ROOT + \"/\" + url.getServiceName() + \"/provider\";\n    watchChildNodeData(newServerNodePath);\n    //根据提供者的 IP 地址，监控每个服务提供者的状态信息变化。注意是所有，而不是单独一个\n    String providerIpStrJson = url.getParameters().get(\"providerIps\");\n    List<String> providerIpList = JSON.parseObject(providerIpStrJson, new TypeReference<List<String>>(){});\n    for (String providerIp : providerIpList) {\n        this.watchNodeDataChange(newServerNodePath + \"/\" + providerIp);\n    }\n}\n```\n\n其中`watchChildNodeData`和`watchNodeDataChange`分别最终调用了`client.getChildren().usingWatcher(watcher).forPath(path);`和`client.getData().usingWatcher(watcher).forPath(path);`\n\n具体来说，这个watcher是一个函数式接口，需要实现其中的`process`方法。以监听服务节点数量的变化为例：\n\n```java\n/**\n * 订阅服务子节点的数据变化（key的变化）\n */\npublic void watchChildNodeData(String newServerNodePath) {\n    zkClient.watchChildNodeData(newServerNodePath, new Watcher() {\n        @Override\n        public void process(WatchedEvent watchedEvent) {\n            String path = watchedEvent.getPath();\n            LOGGER.info(\"[watchChildNodeData] 监听到zk节点下的\" + path + \"节点数据发生变更\");\n            List<String> childrenDataList = zkClient.getChildrenData(path);\n            URLChangeWrapper urlChangeWrapper = new URLChangeWrapper();\n            Map<String, String> nodeDetailInfoMap = new HashMap<>();\n            for (String providerAddress : childrenDataList) {\n                String nodeDetailInfo = zkClient.getNodeData(path + \"/\" + providerAddress);\n                nodeDetailInfoMap.put(providerAddress, nodeDetailInfo);\n            }\n            urlChangeWrapper.setNodeDataUrl(nodeDetailInfoMap);\n            urlChangeWrapper.setProviderUrl(childrenDataList);\n            urlChangeWrapper.setServiceName(path.split(\"/\")[2]);\n            RpcEvent rpcEvent = new RpcUpdateEvent(urlChangeWrapper);\n            RpcListenerLoader.sendEvent(rpcEvent);\n            //收到回调之后在注册一次监听，这样能保证一直都收到消息\n            watchChildNodeData(path);\n        }\n    });\n}\n```\n\n### 五、服务提供者-Service\n\n在这里启动Service，并完成服务的注册等等。\n\n下面`server.startServerApplication();`所做的事就是如第二部分Netty中所作\n\n```java\npublic class RpcServerAutoConfiguration implements InitializingBean, ApplicationContextAware {\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(RpcServerAutoConfiguration.class);\n\n    private ApplicationContext applicationContext;\n\n    @Override\n    public void afterPropertiesSet() throws Exception {\n        Server server = null;\n        Map<String, Object> beanMap = applicationContext.getBeansWithAnnotation(EasyRpcService.class);\n        if (beanMap.size() == 0) {\n            //说明当前应用内部不需要对外暴露服务\n            return;\n        }\n        printBanner();\n        long begin = System.currentTimeMillis();\n        server = new Server();\n\n        // 在这里通过rpc.properties配置文件初始化服务端配置,包括注册地址、端口、registerType、序列化方式等\n        server.initServerConfig();\n\n        for (String beanName : beanMap.keySet()) {\n            Object bean = beanMap.get(beanName);\n            EasyRpcService easyRpcService = bean.getClass().getAnnotation(EasyRpcService.class);\n            ServiceWrapper dataServiceServiceWrapper = new ServiceWrapper(bean, easyRpcService.group());\n            dataServiceServiceWrapper.setServiceToken(easyRpcService.serviceToken());\n            dataServiceServiceWrapper.setLimit(easyRpcService.limit());\n            dataServiceServiceWrapper.setWeight(easyRpcService.weight());\n\n            // 注册中心的注册，将url加入到PROVIDER_URL_SET\n            server.registyService(dataServiceServiceWrapper);\n            LOGGER.info(\">>>>>>>>>>>>>>> [easy-rpc] {} export success! >>>>>>>>>>>>>>> \", beanName);\n        }\n        // 提供回调接口，当jvm进程关闭的时候触发\n        ServerShutdownHook.registryShutdownHook();\n\n        // 在这里才进行了真正的服务注册\n        server.startServerApplication();\n        long end = System.currentTimeMillis();\n        LOGGER.info(\" ================== [{}] started success in {}s ================== \", SERVER_CONFIG.getApplicationName(), ((double) end - (double) begin) / 1000);\n    }\n\n    @Override\n    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {\n        this.applicationContext = applicationContext;\n    }\n\n}\n```\n\n\n\n### 六、服务消费者\n\n利用`bean`的生命周期，和`SpringBoot`提供的`ApplicationListener`接口\n\n```java\n@Slf4j\npublic class RpcClientAutoConfiguration implements BeanPostProcessor, ApplicationListener<ApplicationReadyEvent> {\n\n    private static RpcReference rpcReference = null;\n    private static Client client = null;\n    private volatile boolean needInitClient = false;\n    private volatile boolean hasInitClientConfig = false;\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(RpcClientAutoConfiguration.class);\n\n    @Override\n    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {\n\n        log.info(\"beanName:{}\",beanName);\n        Field[] fields = bean.getClass().getDeclaredFields();\n        for (Field field : fields) {\n            if (field.isAnnotationPresent(EasyRpcReference.class)) {\n                if (!hasInitClientConfig) {\n                    client = new Client();\n                    try {\n                        client.initClientConfig();\n\n                        // 做一些初始化操作，返回的rpcReference对象是一个封装了JDKProxyFactory代理工厂的RpcReference对象\n                        rpcReference = client.initClientApplication();\n                    } catch (Exception e) {\n                        LOGGER.error(\"[IRpcClientAutoConfiguration] postProcessAfterInitialization has error \", e);\n                        throw new RuntimeException(e);\n                    }\n                    hasInitClientConfig = true;\n                }\n                needInitClient = true;\n                EasyRpcReference easyRpcReference = field.getAnnotation(EasyRpcReference.class);\n                try {\n                    field.setAccessible(true);\n                    Object refObj = field.get(bean);\n                    RpcReferenceWrapper rpcReferenceWrapper = new RpcReferenceWrapper();\n                    rpcReferenceWrapper.setAimClass(field.getType());\n                    rpcReferenceWrapper.setGroup(easyRpcReference.group());\n                    rpcReferenceWrapper.setServiceToken(easyRpcReference.serviceToken());\n                    rpcReferenceWrapper.setUrl(easyRpcReference.url());\n                    rpcReferenceWrapper.setTimeOut(easyRpcReference.timeOut());\n                    //失败重试次数\n                    rpcReferenceWrapper.setRetry(easyRpcReference.retry());\n                    rpcReferenceWrapper.setAsync(easyRpcReference.async());\n\n                    // 获取对象的代理对象\n                    refObj = rpcReference.get(rpcReferenceWrapper);\n\n                    // 设置代理对象到bean的field中，此后调用这个bean，实际上调用的都是这个代理对象。\n                    field.set(bean, refObj);\n                    client.doSubscribeService(field.getType());\n                } catch (Throwable e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return bean;\n    }\n\n\n    // ApplicationReadyEvent 是 Spring Boot 提供的事件之一，表示应用程序已经准备好接收请求。\n    // 它是在应用上下文完全初始化并刷新完成后触发的，意味着所有的 Bean 都已经被创建并初始化完成，且应用程序可以正常运行。\n\n    @Override\n    public void onApplicationEvent(ApplicationReadyEvent applicationReadyEvent) {\n        if (needInitClient && client != null) {\n            LOGGER.info(\" ================== [{}] started success ================== \", CLIENT_CONFIG.getApplicationName());\n            // 在这里与服务端建立连接，并且进行服务节点的watch监控\n            client.doConnectServer();\n            // 异步消费阻塞队列中的请求，发送到服务端。\n            client.startClient();\n\n            // 注意：返回结果是在client.initClientApplication()中的ch.pipeline().addLast(new ClientHandler());中设置的\n            // 也就是说，客户端发送请求后，服务端返回的结果是在ClientHandler中设置的。将结果放入到RESP_MAP\n        }\n    }\n}\n```', 0, '2023-09-01 08:02:51', '2023-09-01 08:02:51'),
(23, 2424549811030017, 1, 'Nagle算法是TCP协议中的一种优化算法,用于提高网络利用效率。\n\n它的主要作用是:\n\n（1）合并小的报文段:当有新的小报文段需要发送时,Nagle算法会等待一段时间,将多个小报文段合并成一个大报文段后再发送,从而减少报文段数量,提高网络利用率。\n避免发送过于频繁。\n（2）Nagle算法会在发送一个报文段后等待ACK回复后再发送下一个报文段。这可以避免发送过于频繁,导致网络拥塞。\nNagle算法。\nNagle算法通过设置TCP_NODELAY参数禁用，例如，在我们RPC组件中，就禁用了Nagle算法。', 0, '2023-09-01 13:11:43', '2023-09-01 13:11:43');
INSERT INTO `article_detail` (`id`, `article_id`, `version`, `content`, `deleted`, `create_time`, `update_time`) VALUES
(25, 2424600050855936, 1, '### 记录一个@Builder导致的反序列化错误！\n\n最近在对一个对象进行序列化与反序列化发现一个奇怪的bug。一个简单的序列化与反序列化就会报错。\n\n![image-20230902223410046](C:\\Users\\wcd\\AppData\\Roaming\\Typora\\typora-user-images\\image-20230902223410046.png)\n\n通过打印出来的消息，与类字段也是能够对应上的。\n\n最终经过排查 ，我使用lombok的1.18.24版本，在类上面标注@Builder注解没有无参构造函数，导致反序列化失败。\n\n加上全参构造和无参构造的注解，解决问题：\n\n```java\n@Data\n@Builder\n@AllArgsConstructor\n@NoArgsConstructor\npublic class MailBO {\n    /**\n     * 目标邮箱地址\n     */\n    private String to;\n\n    /**\n     * 标题不能为空\n     */\n    private String title;\n\n    /**\n     * 正文不能为空\n     */\n    private String content;\n\n    /**\n     * 消息id\n     */\n    private String msgId;\n\n}\n```\n\n\n\n', 0, '2023-09-02 15:20:46', '2023-09-02 15:20:46'),
(26, 2424700051904512, 1, '## rabbitmq+定时任务实现邮件发送，保证消息100%投递成功\n\n在技术博客园项目中，我采用了RabbitMQ实现邮件发送。众所周知，消息队列有三个优点：异步、解耦、削峰。\n\n与之对应的，消息队列也会增加系统的复杂性。如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？用 MQ 有个基本原则，就是数据不能多一条，也不能少一条，不能多，就是**重复消费和幂等性**问题。不能少，就是消息的**可靠性**传输。\n\n### 一、理论说明：\n\n首先我们从RabbitMQ架构中看哪些地方会发生消息传输失败：\n\n![image-20230903120545404](C:\\Users\\wcd\\AppData\\Roaming\\Typora\\typora-user-images\\image-20230903120545404.png)\n\n针对这三个地方，我们需要进行以下出来，来保证消息的可靠性传输：\n\n#### 1、从生产者到RabbitMQ：\n\n方法（1）：开启 **RabbitMQ 事务** `channel.txSelect` ，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会 收到异常报错，此时就可以回滚事务 channel.txRollback ，然后重试发送消息；如果收到 了消息，那么可以提交事务 channel.txCommit 。很显然，这种方法大大降低了消息队列的可用性，大大降低了吞吐量。\n\n方法（2）：利用**confirm**机制，confirm是异步的，当消息被成功投递到RabbitMQ，会回调一个ack给生产者。而事务机制是同步的，你提交一个事务之后会阻 塞在那儿。\n\n很显然，我们需要采用方法（2）的confirm机制。\n\n#### 2、RabbitMQ自身弄丢了消息：\n\n这个可能性主要出现在RabbitMQ突然挂掉了，所以我们需要消息的持久化，实现消息的持久化，主要有两个地方：\n\n（1）、queue的持久化\n\n（2）、消息的持久化\n\n#### 3、消费者突然挂掉。\n\n这个和第一个地方（生产者到消费者处）用 RabbitMQ 提供的 ack 机制，简单来说，就是你**必须关闭 RabbitMQ 的自动 ack** ，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，手动 ack。\n\n#### 总结：\n\n![image-20230903121516119](C:\\Users\\wcd\\AppData\\Roaming\\Typora\\typora-user-images\\image-20230903121516119.png)\n\n#### 4、重复消费：幂等性\n\n在一些特定的场景（比如），可能会导致消息被重复消费，比如说：消费者成功消费了信息，但是还没有ack就突然挂掉了，这就会导致消息的重复消费。别小看这一点，这一点在我下方的**bug记录**中就遇到过。\n\n而如何避免这个问题，我们就需要用到数据库的唯一键锁定，我们每次创建消息的时候，将消息写入到数据库中，这样每次消费的时候，先去数据库查询这条消息是否被消费。而数据库不出问题的稳定性，我们可以采用事务来保证。\n\n总的来说：通过mysql的唯一键锁定实现消息消费的幂等性。\n\n\n\n5、定时任务的补充：\n\n当一些特殊情况，导致消费者消费失败，这条消息也会从磁盘中删除，不会再重新投递。（注意，消费者ack或者nack，都会使得消息从RabbitMQ磁盘中删除）。这时候我们可以将数据库该条信息的status设置为fail。\n\n然后后台采用一个定时任务，定时从数据库中查询fail的消息，并且处理这些fail的消息。\n\n\n\n### 二、具体实战：\n\n##### 1、**exchange、queue的声明**：queue必须声明为持久化，这是保证RabbitMQ自身不丢消息的2个必备条件之一。\n\n##### 2、**消息的发送**：\n\n（1）信息持久化设置。\n\n（2）发送失败，Nack重试机制。\n\n（3）数据库的唯一键保证：防止后续重复消费。\n\n**总代码：**\n\n```java\npublic void publishMailerMsg(String exchange,\n                             String routingKey,\n                             MailBO mailBO) {\n\n    String message = JsonUtil.toStr(mailBO);\n\n    // 最多重试2次\n    int retryCount = 0;\n    int maxRetryCount = 2;\n    boolean isOk = false;\n    Channel channel = null;\n    RabbitmqConnection rabbitmqConnection = null;\n    while(retryCount < maxRetryCount && !isOk){\n        try {\n            retryCount++;\n            // 创建连接\n            rabbitmqConnection = RabbitmqConnectionPool.getConnection();\n            Connection connection = rabbitmqConnection.getConnection();\n            // 创建消息通道\n            channel = connection.createChannel();\n            // 开启发布确认模式\n            channel.confirmSelect();\n            // 消息可靠性！：发布消息，并且进行了信息持久化！\n            channel.basicPublish(exchange, routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes());\n            log.info(\"Publish msg: {}\", message);\n\n            // 等待确认消息发布成功\n            if (channel.waitForConfirms()) {\n                log.info(\"Message publish confirmed\");\n                // 存储于数据库中。保证唯一索引。\n                msgLogService.saveMsgLog(mailBO.getMsgId(), CommonConstants.EXCHANGE_EMAIL_DIRECT, CommonConstants.QUERE_KEY_EMAIL, message, MsgLogStatuesConstants.WAIT);\n                isOk = true;\n            } else {\n                log.error(\"Message publish failed\");\n            }\n        } catch (InterruptedException | IOException e) {\n            log.error(\"Failed to publish message\", e);\n        } finally {\n            closeChannelAndConnection(channel, rabbitmqConnection);\n        }\n    }\n    if (!isOk) {\n        log.error(\"Failed to publish message after {} retries\", maxRetryCount);\n        // todo 更新数据库设置为失败，交给定时任务处理\n        msgLogService.updateStatusByMsgId(message, MsgLogStatuesConstants.FAIL);\n    }\n}\n\nprivate void closeChannelAndConnection(Channel channel, RabbitmqConnection rabbitmqConnection) {\n    try {\n        if (channel != null && channel.isOpen()) {\n            channel.close();\n        }\n        if(rabbitmqConnection != null) {\n            RabbitmqConnectionPool.returnConnection(rabbitmqConnection);\n        }\n    } catch (IOException | TimeoutException e) {\n        log.error(\"Failed to close channel or connection\", e);\n    }\n}\n```\n\n##### 3、消息的消费\n\n（1）通过下面的代码实现了消息的**幂等性**：\n\n```java\nif(msgLogDO ==null || msgLogDO.getStatus().equals(MsgLogStatuesConstants.SUCCESS)){\n    log.info(\"信息已经消费过\");\n    return;\n}\n```\n\n（2）注意上方的**ack与nack是必需的**，否则会导致，消息在RabbitMQ中堆积，影响效率，并且会被重复消费。\n\n**总代码：**\n\n```java\n@RabbitListener(queues = CommonConstants.QUERE_NAME_EMAIL)\npublic void rabbitmqSendEmail(String message, Channel channel,  @Header(AmqpHeaders.DELIVERY_TAG) long deliveryTag) throws IOException {\n    log.info(\"Consumer msg: {}\", message);\n    MailBO mailBO = JsonUtil.toObj(message, MailBO.class);\n    MsgLogDO msgLogDO = msgLogService.queryByMsgId(mailBO.getMsgId());\n    log.info(\"msgLogDO:{}\", msgLogDO);\n    if(msgLogDO ==null || msgLogDO.getStatus().equals(MsgLogStatuesConstants.SUCCESS)){\n        log.info(\"信息已经消费过\");\n        return;\n    }\n    if(EmailUtil.sendMail(mailBO.getTitle(), mailBO.getTo(), mailBO.getContent())){\n        log.info(\"成功发送邮件\");\n        msgLogService.updateStatusByMsgId(mailBO.getMsgId(), MsgLogStatuesConstants.SUCCESS);\n        // ack是必需的，因为设置了消息持久化，如果不啊ack，会导致消息堆积。\n        channel.basicAck(deliveryTag, false);\n    }else {\n        log.info(\"发送邮件失败, 交由定时任务重试\");\n        msgLogService.updateStatusByMsgId(mailBO.getMsgId(), MsgLogStatuesConstants.FAIL);\n        // Nack也是必需的，因为设置了消息持久化，\n        channel.basicNack(deliveryTag, false, false);\n    }\n}\n```\n\n##### 4、定时任务\n\n设置为每60秒进行重试。最多重试`MAX_TRY_COUNT` = 2次。\n\n```java\n@Scheduled(cron = \"0/60 * * * * ?\")\nprivate void run(){\n    List<MsgLogDO> msgLogDOS = msgLogService.queryMsgByStatus(MsgLogStatuesConstants.FAIL);\n    log.info(\"定时任务开始执行，查询到{}条消息记录\", msgLogDOS.size());\n    msgLogDOS.forEach(msgLogDO -> {\n        if (msgLogDO.getTryCount() >= MAX_TRY_COUNT) {\n            msgLogService.updateStatusByMsgId(msgLogDO.getMsgId(), MsgLogStatuesConstants.RETRY_FAIL);\n            return;\n        }\n        rabbitmqService.publishMailerMsg(msgLogDO.getExchange(), msgLogDO.getRoutingKey(), JsonUtil.toObj(msgLogDO.getMsg(), MailBO.class));\n        // 重新次数+1\n        msgLogService.updateTryCount(msgLogDO.getMsgId(), msgLogDO.getTryCount() + 1);\n    });\n}\n```\n\n### 三、bug记录\n\n1、记录1：ack错误导致重启机器后的消息重复消费\n\n在`channel.basicAck(deliveryTag, false);`中，我一开始deliveryTag取错了，导致basicAck失败，当时为了排除这个bug，就会不停重启机器，而每次重启机器，都会有“消息已经消费过”的字样，而这个问题就出现在消息没有ack/nack导致的信息重复消费问题。\n\n', 0, '2023-09-03 04:35:57', '2023-09-03 04:35:57');
